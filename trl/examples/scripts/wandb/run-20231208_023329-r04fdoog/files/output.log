  0%|                                                                                                   | 0/246 [00:00<?, ?it/s]You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
/home/as14661/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2632: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.
  warnings.warn(
Could not estimate the number of tokens of the input, floating-point operations will not be computed
  0%|▎                                                                                        | 1/246 [00:34<2:20:00, 34.29s/it]

  1%|▋                                                                                        | 2/246 [00:49<1:33:31, 23.00s/it]

  1%|█                                                                                        | 3/246 [01:04<1:18:37, 19.41s/it]
{'loss': 0.7966, 'learning_rate': 3e-06, 'epoch': 0.01}


  2%|█▊                                                                                       | 5/246 [01:34<1:07:27, 16.79s/it]

  2%|██▏                                                                                      | 6/246 [01:49<1:04:34, 16.14s/it]

  3%|██▌                                                                                      | 7/246 [02:04<1:03:02, 15.83s/it]

  3%|██▉                                                                                      | 8/246 [02:19<1:01:18, 15.45s/it]

  4%|███▎                                                                                     | 9/246 [02:34<1:00:23, 15.29s/it]

  4%|███▋                                                                                      | 10/246 [02:49<59:45, 15.19s/it]
  4%|███▋                                                                                      | 10/246 [02:49<59:45, 15.19s/it]/home/as14661/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2632: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.
